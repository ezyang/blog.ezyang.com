---
title: "Medieval medicine and computers"
date: 2010-11-08 09:00:15
slug: medieval-medicine-and-computers
categories: [Computer Science, Software Engineering]
comments:
    - id: 1427
      author: Jonas Elfström
      date: "2010-11-08 19:09:49"
      content: "Very nice and I kind of agree. Do we need a Karl Popper of CS or is Popper himself enough? As a start it would be nice to bring Turing and Knuth to the masses but unfortunately I have a feeling that Gödel will come around."
    - id: 1429
      author: Geoff H
      date: "2010-11-08 19:36:26"
      content: |
        I dont think it's all that different either.  Good analogy.  :)
        
        CS is great from the HW to the base-OS and programming libraries, and then it loses it's footing as the complexity of state spirals the variables out of control.
    - id: 1430
      author: Tom Dalling
      date: "2010-11-08 19:41:39"
      content: |
        You're not alone. Frederick Brooks writes in the preface to the 20th anniversary edition of The Mythical Man-Month:
        
        "In preparing my retrospective and update of The Mythical Man-Month, I was struck by how few of the propositions asserted in it have been critiqued, proven, or disproven by ongoing software engineering research and experience."
        
        It feels like the majority of software development principles/practices/etc. are based purely on opinion, and maybe some experience if you're lucky, but never based on science. It's completely normal to make bold claims -- such as "language X is better than language Y" or "NoSQL is better than relational databases" -- evidenced only by opinion and anecdotes. Can medical researchers make such bold claims about drugs, supported only by opinion and anecdotes? It's hard to discern the truth when there is so little data collected under reasonable experimental conditions.
        
        What is our equivalent of a double-blind placebo-controlled study? Is such a study possible in our discipline? I'm no scientist, but it seems like software development is difficult thing to run experiments on.
    - id: 1434
      author: "Professor Scrum Von Agile and his Dancing Index Cards | D-Flat"
      date: "2010-11-08 20:12:26"
      content: "[...] to medicine, law, prostitution, building, publishing and almost everything else.  So I read this article with interest.  Although the parallel with practicing vs studyingmedicine is interesting, [...]"
    - id: 1435
      author: Omega
      date: "2010-11-08 20:17:06"
      content: "Computer science (I mean informatics, not the new \"everything about computers\" definition) is doomed"
    - id: 1436
      author: S K
      date: "2010-11-08 20:21:55"
      content: "Modern medicine is no great shakes. The triple bypass doesn't work. Medical students do \"pelvic exams\" on anesthetized women without their consent during other routine operations. It's a mess driven by basic human herd behavior and competition, just like the computer world."
    - id: 1439
      author: Optional
      date: "2010-11-08 23:01:47"
      content: "And then there's this fascinating issue of how it comes to be that \"software engineers\" think they are engineers despite having no degree or training in engineering. Engineering means \"applied science\". It does not mean \"trial and error\", \"write code and debug until it works\", or any other manifestation of an ignorance of the science that should be applied. If computer science is as poorly understood as medicine was in the 1500s, that's unfortunate, but let's not confuse the programming of computers with engineering unless there is some actual science being applied."
    - id: 1445
      author: Quasimodo
      date: "2010-11-09 07:48:20"
      content: "An absurd comparison: as ignorant of the history of medicine, as of computer science."
    - id: 1446
      author: Grosseteste
      date: "2010-11-09 08:35:34"
      content: |
        You reference a 'Cook' who does not appear in your list of works referenced. Would that be Hal Cook?
        
        Despite the rapid acceptance of the circulation. Harvey's theory of generation never caught on, from which we might conclude that every new idea from a software guru has to be judged on its own merits, no matter often s/he was right before.
    - id: 1448
      author: BrainiacV
      date: "2010-11-09 09:35:53"
      content: "Certainly when debugging real-time processes, my colleagues and I sound a bit like doctors as we pass scenarios back and forth to find the bug (\"I think so and so is happening.\"  \"If that was happening, we'd see this and that, we aren't, so it may be whatsit and whosit.\" ...)"
    - id: 1449
      author: Anonymous
      date: "2010-11-09 09:50:35"
      content: |
        Most developers left computer science behind at university (if they even went). We need to see some shining examples of how computer science is going to help us improve reliability, productivity, scaleability etc. 
        
        Remember how all that CS research went into AI and spectacularly failed to deliver very much - I thought computers would be programming themselves by now ?
    - id: 1452
      author: xhevahir
      date: "2010-11-09 10:18:03"
      content: "Is medicine really a science, though?  I would say it's rather a practical art that is informed by science, and that its end is a healthy person.  And while the concept of good health may get pretty complicated, and we may not agree completely about what it involves, a healthy person is at least a final goal.  What, on the other hand, is the goal of software engineering (or software design, or whatever you call it)?  To make software that works?  Software is itself only a means to other ends, and those I think are numerous and varied enough to rule out any systematic treatment of the kind you're proposing."
    - id: 1453
      author: Walker
      date: "2010-11-09 11:02:32"
      content: "Interesting comparison, but I take exception to the term \"software engineer.\"  The vast majority of programmers/developers are not engineers by any stretch of the imagination - the term \"engineer\" is applied to far too many IT positions and it pains me to see an email signature which contains \"Help Desk Engineer.\""
    - id: 1454
      author: Narud Shiro
      date: "2010-11-09 11:44:28"
      content: |
        A short time ago, a friend (and also one of the best programmers I know) told me that, against what almost everybody think, our profession is more a craftsmanship than an engineering. And we realized that this is one of the big causes (not justifications) about why is so hard to planning and release projects in time.
        
        Our develpment 'tools' and frameworks contribute to increase this mess when the code don't do what we expect that do, the documentation and samples are pretty frugal (in case that exists), and after hours (or sometimes days) of test and error, and prays to Saint Google, we found that our code is right, but it need the install of a fix (or a entire update or service pack) to works properly.
        
        Recently I discovered, after alot of tunings in the servers, how to improve up to 1,000% the performance of a slow web app: using Chrome instead IE in the client side. In the same of Saint Bit, tell me how we can apply a scientific method instead the empirical way to solve this kind of situations?
        
        If we are in the same situation that the medicine was five centuries ago, It seems that we are doomed to be empirical artisans other five centuries.
    - id: 1456
      author: Cesium
      date: "2010-11-09 12:26:35"
      content: "Observation and experiment are the core of science; proof and certainty lie in the realm of mathematics. Computer science is in a weird limbo where a few decades ago, engineers started building physical machines that could approximate the theoretical concepts of Turing and Shannon and others. But no matter how theoretically powerful a Turing machine is, it's not very practical. So people built the languages and systems that were useful, which rapidly outstripped the ability of theoreticians to prove anything about them. Programs became analogous to fire, which could be made and controlled by cavemen with no idea of the physics behind it, as well as by the Greeks who examined its properties and concluded it was a basic element. Computers, a creation of humanity -- even as pure software, abstracted away from the limitations and vagaries of physical hardware -- became a part of the natural world, a subject of science, not mathematics. Because the math has not caught up, because what is useful is not always what is simple or logical or understandable, there is the divide between the 'scientists' and the 'engineers', and computers cannot yet fulfill the dreams and ambitions we had for them."
    - id: 1457
      author: Mark
      date: "2010-11-09 12:56:04"
      content: |
        Thought provoking comparison. Can software engineers learn much from medicine's long history? Not until Vesalius and Harvey did practitioners begin to influence medical theorists. Only after old theories were debunked could new discoveries lead to new theories that could improve practice...tenured CS profs take note. Of course, we now live in very different times ;)
        
        I agree that software engineering practice in industry is pretty awful, commercial software quality is abominable, and huge amounts of money and effort are spent on quality improvement initiatives that don't improve quality. Commercial software writers can certainly use some guidance. But consider what drives innovations like the personal computer, mobile computing and social networks. These arose from commercial demand, not the university lab.
        
        OTOH, the OOA/OOP paradigm shift shows that academics in endowed chairs have something to contribute. And the revolution in bioinformatics demands software that can pass scientific peer review. Informatics is not doomed--rather, we're just beginning to glimpse some potential benefits. Maybe the lesson to be learned is that practitioners and academics can and should both learn from one another.
    - id: 1458
      author: Anonymous
      date: "2010-11-09 14:22:40"
      content: "There is indeed a parallel between the calls for \"more formal methods\" and the Four Humours theory, no? Trying to shoehorn some theoretical-sounding abstractions into what is basically a big opaque mess."
    - id: 1459
      author: Lance
      date: "2010-11-09 15:04:41"
      content: "If any one way or one solution worked, everyone would adopt &amp; use it, and the rest would just simply go away...  until such a solution occurs, we will all have to continue in \"the search for Spock\"."
    - id: 1461
      author: g bruno
      date: "2010-11-09 15:35:08"
      content: |
        software in my experience means finding out business rules. ...  what people actually do.  They are unable to describe this.
        Often the answer to eg "what do you do if a transaction is not acknowledged? " is, in effect : "we run about and flap our hands in the air".
    - id: 1463
      author: Zeleres
      date: "2010-11-09 16:42:51"
      content: |
        The responses to this post so far are indicative that you've struck a chord.  I think your best comparison is between medicine quacks and programming frameworks/methodologies.  It seems like every week there is some new methodology that everyone must be crazy not to implement because "look at how successful it was for Company X!".  I don't buy most of these fads and it seems too often I'm saying "yep, saw that coming" when the fads are later shot to pieces (director's cut of Robocop style) in public arenas like Slashdot and Reddit.
        
        Thank you for the thought-provoking impressions and thank you for looking closely at history for guidance in today's crazy world of programming - I hope more people are taking notes.
    - id: 1465
      author: Tanmoy Das (www.dasideen.com)
      date: "2010-11-09 21:29:05"
      content: Good read....
    - id: 1487
      author: General Motors
      date: "2010-11-11 06:07:46"
      content: "Your parable would be interesting if the original story was sound. But medicine is not a science! It's the same old crackpot endevaur as it ever was. And if we forget about that, what exactly is your proposal? Besides negative feelings, do you have a product, business plan, a theory? Legitimization? Yeah, that will fill your pockets, but it is not a solution to this problem. Except if you're maybe in reverse and seeking a problem for a business solution? Are you?"
    - id: 1508
      author: Michael Fever
      date: "2010-11-13 22:49:19"
      content: "Displaying text in full justification is difficult to read for those suffering from dyslexia.  Lose the justification!"
    - id: 1647
      author: Polyprogramer
      date: "2010-12-12 11:44:19"
      content: "\"Those who can do, those who can't teach!\""
---

This is a bit of a provocative post, and its impressions (I dare not promote them to the level of *conclusions*) should be taken with the amount of salt found in a McDonald’s Happy Meal. Essentially, I was doing some reading about medieval medicine and was struck by some of the similarities between it and computer engineering, which I attempt to describe below.

*Division between computer scientists and software engineers.* The division between those who studied medicine, the *physics* (a name derived from physica or natural science) and those who practiced medicine, the *empirics*, was extremely pronounced. There was a mutual distrust—Petrarch wrote, “I have never believed in doctors nor ever will” (Porter 169)—that stemmed in part from the social division between the physics and empirics. Physics would have obtained a doctorate from a university, having studied one of the highest three faculties possible (the others being theology and law), and tended to be among the upper strata of society. In fact, the actual art of medicine was not considered “worthy of study,” though the study of natural science was. (Cook 407).

The division between computer scientists and software engineers is not as bad as the corresponding division in the 1500s, but there is a definite social separation (computer scientists work in academia, software engineers work in industry) and a communication gap between these two communities. In many other fields, a PhD is required to be even considered for a job in your field; here, we see high school students starting up software companies (occasionally successfully) all the time, and if programming Reddit is any indication, there is a certain distaste for purely theoretical computer scientists.

*The unsuitability of pure computer science for the real world.* Though the study of pure medicine was highly regarded during this time, its theories and knowledge were tremendously off the mark. At the start of the 1500s the four humors of Hippocratic medicine were still widely believed: to be struck by disease was to have an imbalance of black bile, yellow bile, phlegm and blood, and thus the cure would be to apply the counteracting humor, and justified such techniques as bloodletting (the practice of purposely bleeding a person). Even the understanding of how the fundamentals of the human body worked were ill-understood: it was not until William Harvey and his *De motu cordis et sanguinis* (1628) that the earlier view that food was concocted in the organs and then flowed outwards via the veins, arteries and nerves to the rest of the body was challenged by the notion of the heart as a pump. (Cook 426) If the circulatory system was true, what did the other organs do? Harvey’s theory completely overturned the existing understanding of how the human body worked, and his theory was quite controversial.

I have enough faith in computer science that I don’t think most of our existing knowledge is fundamentally wrong. But I also think we know tremendously little about the actual nature of computation even at middling sizes, and this is a quite humbling fact. But I am also fundamentally optimistic about the future of computer science in dealing with large systems—more on this at the end.

*Testing instead of formal methods.* The lack of knowledge, however, did stop the *physicians* (as distinct from *physics*) from practicing their medicine. Even the academics recognized the importance of “medieval *practica*; handbooks listing disorders from head to toe with a description of symptoms and treatment.” (Porter 172) The observational (Hippocratic) philosophy, continued to hold great sway: Thomas Sydenham, when asked on the subject of dissection, stated “Anatomy—Botany—Nonsense! Sir, I know an old woman in Covent Garden who understand botany better, and as for anatomy, my butcher can dissect a joint full and well; now, young man, all that is stuff; you must go to the bedside, it is there alone you can learn disease.” (Porter 229)

In the absence of a convincing theoretical framework, empiricism rules. The way to gain knowledge is to craft experiments, conduct observations, and act accordingly. If a piece of code is buggy, how do you fix it? You add debug statements and observe the output, not construct a formal semantics and then prove the relevant properties. The day the latter is the preferred method of choice is a day when practitioners of formal methods across the world will rejoice.

*No silver bullet.* In the absence of reliable medical theories from the physics, quackery flourished in the eighteenth century, a century often dubbed the “Golden Age of Quackery.” (Porter 284) There was no need to explain *why* your wares worked: one simply needed to give a good show (“drawing first a crowd and then perhaps some teeth, both to the accompaniment of drums and trumpets” (Porter 285)), sell a few dozen bottles of your cure, and then move on to the next town. These “medicines” would claim to do anything from cure cancer to restore youth. While some of the quacks were merely charlatans, others earnestly believed in the efficacy of their treatments, and occasionally a quack remedy was actually effective.

I think the modern analogue to quackery are software methodology in all shapes in sizes. Like quack medicines, some of these may be effective, but in the absence of scientific explanations we can only watch the show, buy in, and see if it works. And we can’t hope for any better until our underlying theories are better developed.

*The future.* Modern medical science was eventually saved, though not before years of inadequate theories and quackery had brought it to a state of tremendous disrepute. The *complexity* of the craft had to be *legitimized*, but this would not happen until a powerful scientific revolution built the foundations of modern medical practice.

------------------------------------------------------------------------

Works referenced:

- Porter, Roy. *The Greatest Benefit To Mankind.* Fontana Press: 1999.
- Park, Katherine; Daston, Lorraine. *The Cambridge History of Science: Volume 3, Early Modern Science.*
